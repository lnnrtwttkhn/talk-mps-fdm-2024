---
title: "{{< var title >}}"
subtitle: |
  {{< var subtitle >}}
  
  [{{< fa display >}} Slides]({{< var website >}}) |
  [{{< fa brands github >}} Source]({{< var source >}})
  
  {{< var license-badge >}}
  {{< var doi-badge >}}
date: today
engine: knitr
execute:
  eval: false
---

## About

:::: {.columns}
::: {.column width="35%"}

![](images/photo-wittkuhn-uhh.jpg)

#### Dr. Lennart Wittkuhn

{{< fa envelope >}} [{{< var email >}}]({{< var mailto >}})<br>
{{< fa home-user >}} [{{< var homepage >}}]({{< var homepage >}})<br>
{{< fa brands mastodon >}} [Mastodon]({{< var mastodon >}})
{{< fa brands github >}} [GitHub]({{< var github >}})
{{< fa brands linkedin >}} [LinkedIn]({{< var linkedin >}})
:::

::: {.column width="65%"}

::: {.fragment}

### About me

{{< fa user-tie >}} I am a **Postdoctoral Research Data Scientist** in Cognitive Neuroscience at the [Institute of Psychology](https://www.psy.uni-hamburg.de/en.html) at the [University of Hamburg](https://www.psy.uni-hamburg.de/en/arbeitsbereiche/lern-und-veraenderungsmechanismen.html) (PI: Nicolas Schuck)

{{< fa graduation-cap >}} **BSc Psychology** & **MSc Cognitive Neuroscience** (TU Dresden), **PhD Cognitive Neuroscience** (Max Planck Institute for Human Development)

{{< fa brain >}} I study **the role of fast neural memory reactivation** in the human brain, applying **machine learning** and **computational modeling** to **fMRI** data

{{< fa code >}} I am passionate about **computational reproducibility**, **research data management**, **open science** and tools that improve the scientific workflow

{{< fa info-circle >}} Find out more about my work on [my website]({{< var homepage >}}), [Google Scholar]({{< var scholar >}}) and [ORCiD]({{< var orcid-link >}})

:::

::: {.fragment}

### About this presentation

{{< fa display >}} **Slides:** [{{< var website >}}]({{< var website >}})

{{< fa brands github >}} **Source:** [{{< var source >}}]({{< var source >}})

{{< fa laptop-code >}} **Software:** Reproducible slides built with [Quarto](https://quarto.org/) and deployed to [GitHub Pages](https://pages.github.com/) using [GitHub Actions](https://github.com/features/actions) for continuous integration & deployment

{{< fa file-contract >}} **License:** {{< var license-long >}}

{{< fa comments >}} **Contact:** Feedback or suggestions via [email]({{< var mailto >}}) or [GitHub issues]({{< var issues >}}). Thank you!


:::
:::
::::

# Scientific building blocks are not static

## We need version control

:::: {.columns}

::: {.column width="42%"}
::: {.fragment}
... for **code** (text files)
![](images/phd-comic-version-control-code-cropped-upper.gif)
:::
::: {.fragment}
![[&copy; Jorge Cham (phdcomics.com)](http://phdcomics.com/comics/archive/phd101212s.gif)](images/phd-comic-version-control-code-cropped-lower.gif)
:::
:::

::: {.column width="58%"}
::: {.fragment}
... for **data** (binary files)
![[&copy; Jorge Cham (phdcomics.com)](http://phdcomics.com/comics/archive/phd052810s.gif)](images/phd-comic-version-control-data.gif)
:::
:::
::::

::: {.fragment}
### If everything is relevant, track everything.
:::

::: {.notes}
- Analysis code, manuscripts and other files evolve
- Rewrite, fix bugs, add functions, refactor, extend, ...
- Version control is relevant for anyone who wants to track the evolution of digital objects
:::

## What are Git and DataLad?

:::: {.columns}

::: {.column width="50%"}
::: {.fragment}
![[git-scm.com](https://git-scm.com/) (Logo by Jason Long; License: [CC BY 3.0 Unported](https://git-scm.com/downloads/logos))](images/git-logo-full.svg){fig-align="center" width=50%}

- most popular version control system
- free, [open-source](https://github.com/git) command-line tool
- graphical user interfaces exist, e.g., [GitKraken](https://www.gitkraken.com/)
- standard tool in the software industry
- 100 million [GitHub](https://github.com/) users ^[(Source: [Wikipedia](https://en.wikipedia.org/wiki/GitHub))]
:::
:::

::: {.column width="50%"}
::: {.fragment}
![[datalad.org](https://www.datalad.org/)](images/datalad-logo-full.svg){fig-align="center" width=50%}

- "Git for (large) data"
- free, [open-source](https://github.com/datalad/datalad) command-line tool
- builds on top of [Git](https://git-scm.com/) and [git-annex](https://git-annex.branchable.com/)
- **allows to version control arbitrarily large datasets** ^[see DataLad dataset of 80TB / 15 million files from the Human Connectome Project (see [details](https://handbook.datalad.org/en/latest/usecases/HCP_dataset.html#usecase-hcp-dataset))]
- graphical user interface exists: [DataLad Gooey](http://docs.datalad.org/projects/gooey/en/latest/index.html)
:::
:::

::::

## Version Control with DataLad

:::: {.columns}
::: {.column width="50%"}
::: {.fragment}
![from the [Datalad Handbook](https://handbook.datalad.org/en/latest/intro/executive_summary.html) (License: [CC BY-SA 4.0](https://handbook.datalad.org/en/latest/licenses.html))](images/datalad-dataset.svg){fig-align="center" width=84%}

```bash
datalad create mydataset
```
:::
:::
::: {.column width="50%"}
::: {.fragment}
![from the [Datalad Handbook](https://handbook.datalad.org/en/latest/intro/executive_summary.html) (License: [CC BY-SA 4.0](https://handbook.datalad.org/en/latest/licenses.html))](images/datalad-local_wf.svg){fig-align="center" width=100%}

```bash
datalad save -m "save large dataset"
```
:::
:::
::::

::: {.notes}
- DataLad knows two things: Datasets and files
- Every file you put into a in a dataset can be easily version-controlled, regardless of size
:::

## Data in DataLad datasets are either stored in Git or git-annex

![from the [Datalad Handbook](https://handbook.datalad.org/en/latest/index.html#) (License: [CC BY-SA 4.0](https://handbook.datalad.org/en/latest/licenses.html))](images/datalad-publishing-gitvsannex.svg){fig-align="center" width=100%}

:::: {.columns}
::: {.column width="50%"}
#### Git

- handles small files well (text, code)
- file contents are in Git history and will be shared
- Shared with every dataset clone
- Useful: Small, non-binary, frequently modified files 
:::
::: {.column width="50%"}
#### git-annex

- handles all types and sizes of files well
- file contents are in the annex. Not necessarily shared
- Can be kept private on a per-file level
- Useful: Large files, private files
:::
::::

# Science is build from modular units

## Science is build from modular units

::::: {.columns}
:::: {.column width="50%"}
::: {.fragment}
### Research as a sequence
![from the [Datalad Handbook](https://handbook.datalad.org/en/latest/intro/executive_summary.html) (License: [CC BY-SA 4.0](https://handbook.datalad.org/en/latest/licenses.html))](images/datalad-submodule-setup.svg){fig-align="center" width=104%}
:::
::: {.fragment}
- Everything is in one big project folder
- In which modules should we put each step?
- Prior works (algorithm development, empirical data, etc.) are combined to produce novel results with to goal of a publication
- Aggregation across time and contributors
- Aiming for (but often failing) to be reproducible
:::
::::
:::: {.column width="50%"}
::: {.fragment}
### Research as a cycle
![[Turing Way!](https://www.datalad.org/)](images/turing-way-research-cycle.svg){fig-align="center" width=80%}
:::
::: {.fragment}
#### What we need
- Git can struggle with 1M+ files or 100k+ commits
- Develop scientific outputs as modular but linked units
- Independently update and develop data sources
- Manage access to public / private datasets
:::
::::
:::::

::: {.notes}
- Project-specific which data to put where
:::

## Dataset nesting

- seamless nesting of modular datasets in hierarchical super-/sub-dataset relationships
- based in Git submodules, but mono-repo feeling thanks to recursive operations
- overcomes scaling issues with large amounts of files (Example: Human Connectome Project)
- modularizes research components for transparency, reuse and access management

![from the [Datalad Handbook](https://handbook.datalad.org/en/latest/basics/101-106-nesting.html) (License: [CC BY-SA 4.0](https://handbook.datalad.org/en/latest/licenses.html))](images/datalad-linkage-subds.svg){fig-align="center" width=104%}

## Example

![from the [Datalad Handbook](https://handbook.datalad.org/en/latest/basics/101-106-nesting.html) (License: [CC BY-SA 4.0](https://handbook.datalad.org/en/latest/licenses.html))](images/datalad-linkage-subds.svg){width="40%"}

:::: {.columns}
::: {.column width="55%"}
::: {.fragment}
First, let's create a new data analysis dataset:
```{bash}
#| code-line-numbers: "1"
datalad create -c yoda myanalysis
[INFO   ] Creating a new annex repo at /tmp/myanalysis
[INFO   ] Scanning for unlocked files (this may take some time)
[INFO   ] Running procedure cfg_yoda
[INFO   ] == Command start (output follows) =====
[INFO   ] == Command exit (modification check follows) =====
create(ok): /tmp/myanalysis (dataset)
```
:::
:::
::: {.column width="45%"}
::: {.fragment}
`-c yoda` initializes useful structure:
```{bash}
tree
.
├── CHANGELOG.md
├── README.md
└── code
    └── README.md
2 directories, 3 files
```
:::
:::
::::

:::: {.columns}
::: {.column width="55%"}
::: {.fragment}
We install analysis input data as a subdataset to the dataset:
```{bash}
#| code-line-numbers: "1"
datalad clone -d . https://github.com/datalad-handbook/iris_data.git input/
[INFO   ] Remote origin not usable by git-annex; setting annex-ignore
install(ok): input (dataset)
add(ok): input (dataset)
add(ok): .gitmodules (file)
save(ok): . (dataset)
action summary:
  add (ok: 2)
  install (ok: 1)
  save (ok: 1)
```
:::
:::
::: {.column width="45%"}
::: {.fragment}
`input` is a regular folder inside `myanalysis`
```{bash}
#| code-line-numbers: "7,8"
tree
.
├── CHANGELOG.md
├── README.md
├── code
│   └── README.md
└── input
    └── iris.csv
3 directories, 4 files
```
:::
:::
::::

## Modular units with clear provenance

:::: {.columns}
::: {.column width="55%"}
::: {.fragment}
```{bash}
#| code-line-numbers: "8-12,19"
git diff HEAD~1
diff --git a/.gitmodules b/.gitmodules
new file mode 100644
index 0000000..fc69c84
--- /dev/null
+++ b/.gitmodules
@@ -0,0 +1,5 @@
+[submodule "input"]
+       path = input
+       url = https://github.com/datalad-handbook/iris_data.git
+       datalad-id = 5800e71c-09f9-11ea-98f1-e86a64c8054c
+       datalad-url = https://github.com/datalad-handbook/iris_data.git
diff --git a/input b/input
new file mode 160000
index 0000000..b9eb768
--- /dev/null
+++ b/input
@@ -0,0 +1 @@
+Subproject commit b9eb768c145e4a253d619d2c8285e540869d2021
```
:::
:::
::: {.column width="45%"}
::: {.fragment}
![from the [Datalad Handbook](https://handbook.datalad.org/en/latest/basics/101-106-nesting.html) (License: [CC BY-SA 4.0](https://handbook.datalad.org/en/latest/licenses.html))](images/datalad-linkage.svg){fig-align="center" width=100%}
:::
:::
::::

:::: {.columns}
::: {.column width="55%"}
::: {.fragment}
We know **exactly**:

1. where the subdataset comes from
1. which version of the subdataset is installed

- We can update each subdataset independently
:::
:::
::: {.column width="45%"}
::: {.fragment}
![[Turing Way!](https://www.datalad.org/)](images/turing-way-provenance.svg){fig-align="center" width=100%}
:::
:::
::::

# Science is exploratory, multi-stepped and iterative

## Reusing past work is hard

![[Turing Way!](https://www.datalad.org/)](images/phd-comic-scratch.gif){fig-align="center" width=70%}

> Your number 1 collaborator if yourself from 6 months ago and they don't answer emails.

> "Shit, which version of which script produced these outputs from which version of what data?"

> "Shit, why buttons did I click and in which order did I use all those tools?"


## datalad-run

::::: {.fragment}
:::: {.columns}
::: {.column width="50%"}
**datalad run** wraps around anything expressed in a command line call and saves the dataset modifications resulting from the execution.
:::
::: {.column width="50%"}
![](images/datalad-run-basic.svg){fig-align="center" width="80%"}
:::
::::
:::::

::::: {.fragment}
:::: {.columns}
::: {.column width="50%"}
**datalad rerun** repeats captured executions. 
If the outcomes differ, it saves a new state of them.
:::
::: {.column width="50%"}
![](images/datalad-rerun.svg){fig-align="center" width="80%"}
:::
::::
:::::

::::: {.fragment}
:::: {.columns}
::: {.column width="50%"}
**datalad containers-run** executes command line calls inside a tracked software container and saves the dataset modifications resulting from the execution.
:::
::: {.column width="50%"}
![[DataLad Handbook](https://handbook.datalad.org/en/latest/basics/basics-run.html)](images/datalad-containers-run-basic.svg){fig-align="center" width="80%"}
:::
::::
:::::

## Example: "Let me just quickly copy those files ..."

### Without datalad run

::::: {.columns}
:::: {.column width="50%"}
::: {.fragment}
Researcher writes some Python code to copy files:
```python
for sourcefile, dest in zip(glob(path_source), glob(path_dest)):
  destination = path.join(dest, Path(sourcefile).name)
  shutil.move(sourcefile, destination)
```
::: {.fragment}
`glob` does not sort! :scream:
:::
:::
::::
:::: {.column width="25%"}
::: {.fragment}
```{bash}
#| code-line-numbers: "1,3,5,7,9"
source/
├── sub-01
│   └── sub-01-events.tsv
├── sub-02
│   └── sub-02-events.tsv
├── sub-03
│   └── sub-03-events.tsv
├── sub-04
│   └── sub-04-events.tsv
[...]
```
:::
::::
:::: {.column width="25%"}
::: {.fragment}
```{bash}
#| code-line-numbers: "1,3,5,7,9"
destination/
├── sub-01
│   └── sub-03-events.tsv
├── sub-02
│   └── sub-01-events.tsv
├── sub-03
│   └── sub-04-events.tsv
├── sub-04
│   └── sub-02-events.tsv
[...]
```
:::
::::
:::::

Researcher shares `analysis` with collaborators.


### With datalad run

::::: {.columns}
:::: {.column width="50%"}
::: {.fragment}
Researcher uses `datalad-run` to copy files:
```{bash}
$ datalad run -m "Copy event files" \
"for sub in eventfiles;
    do mv ${sub}/events.tsv analysis/${sub}/events.tsv;
done"
```
:::
::::
:::: {.column width="45%"}
::: {.fragment}
bla
:::
::::
:::::

# Science is collaborative & distributed

## Summary

### Scientific building blocks are not static: Version Control all the things

### Science is modular: Nesting

### Towards science as open-source knowledge development

## Thank you!

:::: {.columns}
::: {.column width="35%"}

![](images/photo-wittkuhn-uhh.jpg)

#### Dr. Lennart Wittkuhn

{{< fa envelope >}} [{{< var email >}}]({{< var mailto >}})<br>
{{< fa home-user >}} [{{< var homepage >}}]({{< var homepage >}})<br>
{{< fa brands mastodon >}} [Mastodon]({{< var mastodon >}})
{{< fa brands github >}} [GitHub]({{< var github >}})
{{< fa brands linkedin >}} [LinkedIn]({{< var linkedin >}})

:::
::: {.column width="65%"}

::: {layout-ncol=2}
![](images/uhh-logo.svg){width=50%}

![](images/mpib-logo.png){width=70%}
:::

{{< fa image >}} **Images:** [Scriberia with The Turing Way community](https://doi.org/10.5281/zenodo.3332807) (License: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/))

{{< fa display >}} **Slides:** [{{< var website >}}]({{< var website >}})

{{< fa brands github >}} **Source:** [{{< var source >}}]({{< var source >}})

{{< fa laptop-code >}} **Software:** Reproducible slides built with [Quarto](https://quarto.org/) and deployed to [GitHub Pages](https://pages.github.com/) using [GitHub Actions](https://github.com/features/actions) for continuous integration & deployment

{{< fa file-contract >}} **License:** {{< var license-long >}}

{{< fa comments >}} **Contact:** Feedback or suggestions via [email]({{< var mailto >}}) or [GitHub issues]({{< var issues >}}). Thank you!

:::
::::